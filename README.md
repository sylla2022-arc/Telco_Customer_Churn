# MLOps Pipeline Project - Telco Customer Churn Prediction and Monitoring

## ğŸ“Œ Objectif

Ce projet a pour but de construire un pipeline de Machine Learning complet, de l'ingestion des donnÃ©es Ã  la mise en production, pour prÃ©dire si un client va se dÃ©sabonner ou non et monitorer le model en cas de derive. Dans ce projet, je reponds Ã  la problÃ©matique commune, pourquoi perdons nous des clients sans se rendre compte? 

---

##  CompÃ©tences mises en Å“uvre

- **MLOps & CI/CD** : Pipeline modulaire, gestion des artefacts, structuration type production
- **Data Engineering** : Ingestion, validation, transformation avec versioning
- **Machine Learning** : ModÃ©lisation non supervisÃ©e (Classification), optimisation
- **Outils** : MLflow, Docker, AWS(EC2, ECR), GitHub, Python, Scikit-learn, Pandas, NumPy, PyYAML
- **Structuration modulaire** : Architecture basÃ©e sur `src/` avec sÃ©paration des bouts
- **Docker & CI/CD pour automatisation du dÃ©ploiement**

---

## Jeu de donnÃ©es

- **Nom** : [Teco Customer Churn Open Data](https://www.kaggle.com/datasets/blastchar/telco-customer-churn)
- **Description** : DonnÃ©es sur les comportement des clients (Charge, Contract, genre, PaymentMethodx, etc.)
- **TÃ¢che** : Classification sur la variable cible `Churn`

---

## Pipeline MLOps


### Ã‰tapes du pipeline :

1. **Data Ingestion** :
   - Chargement des donnÃ©es brutes
   - Stockage dans un dossier artifact/raw

2. **Data Validation** :
   - VÃ©rification du schÃ©ma
   - DÃ©tection du statut (Feature col / Traget col missing ou non )
   - Branchement d'Evidently pour la derive

3. **Data Transformation** :
   - PrÃ©traitement (encodage, imputation, scaling)
   - Traitement des valeurs manquantes et conversion de type , suppression de cols inutiles
   - Sauvegarde du preprocessor (.pkl)
   - Sauvegarde des arrays transformÃ©s (.npy)

4. **Model Training** :
   - EntraÃ®nement du model unique Catboostclassifier
   - Recuperation des metrique
   - Branchement d'Evidently pour la derive
   - Sauvegarde du modÃ¨le final (.pkl)

5. **Tracking & Versioning** :
   - **DVC** pour versionner : donnÃ©es, transformations, modÃ¨le
   - **MLflow** pour tracer les expÃ©riences (paramÃ¨tres, mÃ©triques, artefacts)

---

## Pipeline visuel
```mermaid

graph LR
    A[Data Ingestion] --> B[Data Validation]
    B --> C[Data Transformation]
    C --> D[Model Training]

    %% Sous-graphe vertical sans titre visible (label = " ")
    subgraph Vertical_Flow[ ]
      direction TB
      E[Model Deployment]
      F[Model Monitoring]
      G[Retraining]
    end
    
    D --> E
    
    B --> H[Mlflow Evidently]
    
    H --> I[Data Drift]
    H --> J[Data Quality Checks]

    id1(((On collecte les donnÃ©es, on entraÃ®ne le modÃ¨le,
    on dÃ©ploie, on surveille performance & qualitÃ© des donnÃ©es --Mlflow, Evidently-- 
    Sylla)))
```
---

## ğŸš€ Deploiement sur EC2

- Configurationde  EC2  sur aws
- DÃ©ploiement sur le cloud (fastapi + streamlit)
    - FastAPI â†’ http://<Elastic-IP>:8000
    - Streamlit â†’ http://<Elastic-IP>:8501
- Automatisation avec GitHub Actions

---

## ğŸ”— Liens utiles

- [DonnÃ©es Kaggle - Telco Churn Open Data](https://www.kaggle.com/datasets/blastchar/telco-customer-churn)
- [GitHub du projet](https://github.com/sylla2022-arc/Telco_Customer_Churn)
- [MLflow UI / Evidently Dashboard](https://docs.evidentlyai.com/docs/library/evaluations_overview)

---

## ğŸ‘¤ Auteur

- **Nom** : Mahamadou SYLLA
- **RÃ´le** : Data Scientist spÃ©cialisÃ© en MLOps
- **Contact** : [LinkedIn](https://www.linkedin.com/in/mahamadou-sylla/) | [GitHub](https://github.com/sylla2022-arc)
